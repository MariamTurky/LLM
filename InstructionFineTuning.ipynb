{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6792dbe3",
   "metadata": {},
   "source": [
    "## STEP 1: PREPARING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c0f875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import ssl\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c5f92e",
   "metadata": {},
   "source": [
    "### CONVERTING INSTRUCTIONS INTO ALPACA FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "126df00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad09fb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c862a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57dd90",
   "metadata": {},
   "source": [
    "### SPLITTING DATASET INTO TRAIN-TEST-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac75d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14aa84a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d1ddcd",
   "metadata": {},
   "source": [
    "## STEP 2: ORGANIZING DATA INTO TRAINING BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77d09ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de084793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a28d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b448232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs, targets = custom_collate_draft(batch)\n",
    "print(inputs)\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab078c3",
   "metadata": {},
   "source": [
    "In the following code, we modify our custom collate function to replace tokens with ID 50256 with -100 in the target lists.\n",
    "\n",
    "Additionally, we introduce an allowed_max_length parameter to optionally limit the length of the samples.\n",
    "\n",
    "This adjustment will be useful if you plan to work with your own datasets that exceed the 1024- token context size supported by the GPT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bb130f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "640457e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcb4f6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43bec44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fcf9a4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82790975",
   "metadata": {},
   "source": [
    "## STEP 3: CREATING DATALOADERS FOR AN INSTRUCTION DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdc23228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abebb06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "183743e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18e2406f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9079e7",
   "metadata": {},
   "source": [
    "## STEP 4: LOADING A PRETRAINED LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12421a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad653364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
    "            GELU(), ## Activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b6e0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        # 2*4*768\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "        # 2*4*768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e6ac236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75cab85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "536185fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a85e1f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaahm\\AppData\\Roaming\\Python\\Python310\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaahm\\AppData\\Roaming\\Python\\Python310\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaahm\\AppData\\Roaming\\Python\\Python310\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaahm\\AppData\\Roaming\\Python\\Python310\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaahm\\AppData\\Roaming\\Python\\Python310\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaahm\\AppData\\Roaming\\Python\\Python310\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaahm\\AppData\\Roaming\\Python\\Python310\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download3 import download_and_load_gpt2\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5720acb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5568d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "117d152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "438810eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36e153d",
   "metadata": {},
   "source": [
    "## STEP 5: FINETUNING THE LLM ON INSTRUCTION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "968e9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "\n",
    "    ###Input batch:\n",
    " ###tensor([[6109, 3626, 6100,  345],\n",
    "        ##[6109, 1110, 6622,  257]])\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c91acfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        \n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "876b9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "        \n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19a234c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8258963108062742\n",
      "Validation loss: 3.7619214057922363\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72201879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.102\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.945\n",
      "Ep 1 (Step 000015): Train loss 0.856, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.753, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.798, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.790\n",
      "Ep 1 (Step 000050): Train loss 0.662, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.764\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.652, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.729\n",
      "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.709\n",
      "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
      "Ep 1 (Step 000095): Train loss 0.500, Val loss 0.681\n",
      "Ep 1 (Step 000100): Train loss 0.502, Val loss 0.677\n",
      "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.667\n",
      "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Training completed in 26.09 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18b7fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c18609d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7796e4",
   "metadata": {},
   "source": [
    "## STEP 6: EXTRACTING AND SAVING RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f34063fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A thunderstorm is a type of cloud that typically forms in the atmosphere over a region of high pressure. It typically produces a strong wind that blows across the area, creating a dense, dense cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is George Bernard Shaw.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a3924534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [30:06<00:00, 16.42s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c723c219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91338d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "# Load model via\n",
    "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd078d3a",
   "metadata": {},
   "source": [
    "## STEP 7: EVALUATING THE FINE-TUNED LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0f40c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2578e41",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "\n",
    "Step 1: Create the data payload as a dictionary\n",
    "    \n",
    "Step 2: Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    \n",
    "Step 3: Create a request object, setting the method to POST and adding necessary headers\n",
    "    \n",
    "Step 4: Send the request and capture the response\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "    prompt,\n",
    "    model=\"llama3\",\n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "    \n",
    "):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    # Create a request object, setting the method to POST and adding necessary headers\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # Send the request and capture the response\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        # Read and decode the response\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923400bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dcbd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f183a9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "The following generate_model_scores function uses a modified the prompt telling the\n",
    "model to \"Respond with the integer number only.\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5439349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in test_data[:2]:\n",
    "    prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry['model_response']}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "    score = query_model(prompt, model)\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt, model))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaabbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb1d71f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
